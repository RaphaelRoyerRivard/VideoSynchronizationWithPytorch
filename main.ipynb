{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn To Synchronize Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR To use wandb on Windows, you need to run the command \"wandb run python <your_train_script>.py\"\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import sync_net\n",
    "import trainer\n",
    "import metrics\n",
    "import data_loader\n",
    "reload(sync_net)\n",
    "reload(trainer)\n",
    "reload(metrics)\n",
    "reload(data_loader)\n",
    "from sync_net import reset_first_layer, replace_last_layer, add_sigmoid_activation, TripletNet, MultiSiameseNet, TripletLoss, CosineSimilarityTripletLoss, LosslessTripletLoss, MultiSiameseCosineSimilarityLoss\n",
    "from data_loader import get_datasets, get_test_set, get_multisiamese_datasets\n",
    "from trainer import fit\n",
    "from metrics import EmbeddingL2DistanceMetric, EmbeddingCosineSimilarityMetric\n",
    "import wandb\n",
    "wandb.init(project=\"learn-to-synchronize-videos\")\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "embedding_net = models.resnet50(pretrained=True)\n",
    "reset_first_layer(embedding_net)\n",
    "replace_last_layer(embedding_net, 16)\n",
    "# embedding_net = add_sigmoid_activation(embedding_net)  # Use only with LosslessTripletLoss\n",
    "# model = TripletNet(embedding_net)\n",
    "model = MultiSiameseNet(embedding_net)\n",
    "model.cuda(0)\n",
    "model = nn.DataParallel(model).cuda()\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# loss_fn = TripletLoss(margin=0.5)\n",
    "# loss_fn = CosineSimilarityTripletLoss(margin=0.5)\n",
    "# loss_fn = LosslessTripletLoss()\n",
    "loss_fn = MultiSiameseCosineSimilarityLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 100\n",
    "start_epoch = 0\n",
    "save_path = r\"C:\\Users\\root\\Projects\\VideoSynchronizationWithPytorch\\trainings\\angio_seq_multisiamese\"\n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)\n",
    "wandb.config.lr = lr\n",
    "wandb.config.optimizer = type(optimizer)\n",
    "wandb.config.loss_fn = type(loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angio sequence triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = r'C:\\Users\\root\\Data\\Angiographie'\n",
    "validation_path = r'C:\\Users\\root\\Data\\Angiographie\\KR-11'\n",
    "training_set, validation_set = get_datasets(training_path, validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angio sequence multi siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 valid frames in C:\\Users\\root\\Data\\Angiographie\\AA-4\\export\\LCA_30LAO25CAU\n",
      "110 valid frames in C:\\Users\\root\\Data\\Angiographie\\AA-4\\export\\LCA_30RAO\n",
      "104 valid frames in C:\\Users\\root\\Data\\Angiographie\\AA-4\\export\\LCA_30RAO25CAU\n",
      "78 valid frames in C:\\Users\\root\\Data\\Angiographie\\AA-4\\export\\LCA_AP\n",
      "79 valid frames in C:\\Users\\root\\Data\\Angiographie\\AA-4\\export\\LCA_LAT\n",
      "121 valid frames in C:\\Users\\root\\Data\\Angiographie\\AA-4\\export\\RCA_AP\n",
      "113 valid frames in C:\\Users\\root\\Data\\Angiographie\\AA-4\\export\\RCA_LAT\n",
      "75 valid frames in C:\\Users\\root\\Data\\Angiographie\\ABL-5\\export\\LCA_30LAO25CRA\n",
      "78 valid frames in C:\\Users\\root\\Data\\Angiographie\\ABL-5\\export\\LCA_30RAO\n",
      "85 valid frames in C:\\Users\\root\\Data\\Angiographie\\ABL-5\\export\\LCA_AP\n",
      "85 valid frames in C:\\Users\\root\\Data\\Angiographie\\ABL-5\\export\\LCA_LAT\n",
      "39 valid frames in C:\\Users\\root\\Data\\Angiographie\\ABL-5\\export\\RCA_AP\n",
      "39 valid frames in C:\\Users\\root\\Data\\Angiographie\\ABL-5\\export\\RCA_LAT\n",
      "48 valid frames in C:\\Users\\root\\Data\\Angiographie\\AC-1\\export\\LCA_40RA015CAU\n",
      "44 valid frames in C:\\Users\\root\\Data\\Angiographie\\AC-1\\export\\LCA_45LAO\n",
      "49 valid frames in C:\\Users\\root\\Data\\Angiographie\\AC-1\\export\\LCA_AP\n",
      "51 valid frames in C:\\Users\\root\\Data\\Angiographie\\AC-1\\export\\LCA_LAT\n",
      "54 valid frames in C:\\Users\\root\\Data\\Angiographie\\AC-1\\export\\RCA_AP\n",
      "60 valid frames in C:\\Users\\root\\Data\\Angiographie\\AC-1\\export\\RCA_LAT\n",
      "51 valid frames in C:\\Users\\root\\Data\\Angiographie\\ALR-2\\export\\LCA_30LAO25CRA\n",
      "46 valid frames in C:\\Users\\root\\Data\\Angiographie\\ALR-2\\export\\LCA_30RAO\n",
      "48 valid frames in C:\\Users\\root\\Data\\Angiographie\\ALR-2\\export\\LCA_AP\n",
      "49 valid frames in C:\\Users\\root\\Data\\Angiographie\\ALR-2\\export\\LCA_LAT\n",
      "62 valid frames in C:\\Users\\root\\Data\\Angiographie\\ALR-2\\export\\RCA_AP\n",
      "53 valid frames in C:\\Users\\root\\Data\\Angiographie\\JEL-10\\export\\LCA_30RA025CAU\n",
      "45 valid frames in C:\\Users\\root\\Data\\Angiographie\\JEL-10\\export\\LCA_30RAO\n",
      "31 valid frames in C:\\Users\\root\\Data\\Angiographie\\JEL-10\\export\\LCA_AP\n",
      "70 valid frames in C:\\Users\\root\\Data\\Angiographie\\JEL-10\\export\\LCA_LAT\n",
      "65 valid frames in C:\\Users\\root\\Data\\Angiographie\\JEL-10\\export\\RCA_AP\n",
      "44 valid frames in C:\\Users\\root\\Data\\Angiographie\\JEL-10\\export\\RCA_LAT\n",
      "84 valid frames in C:\\Users\\root\\Data\\Angiographie\\KC-3\\export\\LCA_30RAO\n",
      "99 valid frames in C:\\Users\\root\\Data\\Angiographie\\KC-3\\export\\LCA_30RAO25CAU\n",
      "82 valid frames in C:\\Users\\root\\Data\\Angiographie\\KC-3\\export\\LCA_AP\n",
      "75 valid frames in C:\\Users\\root\\Data\\Angiographie\\KC-3\\export\\LCA_LAT\n",
      "94 valid frames in C:\\Users\\root\\Data\\Angiographie\\KC-3\\export\\RCA_AP\n",
      "107 valid frames in C:\\Users\\root\\Data\\Angiographie\\KC-3\\export\\RCA_LAT\n",
      "50 valid frames in C:\\Users\\root\\Data\\Angiographie\\MAL-8\\export\\LCA_AP\n",
      "47 valid frames in C:\\Users\\root\\Data\\Angiographie\\MAL-8\\export\\LCA_LAT\n",
      "41 valid frames in C:\\Users\\root\\Data\\Angiographie\\MAL-8\\export\\RCA_AP\n",
      "41 valid frames in C:\\Users\\root\\Data\\Angiographie\\MAL-8\\export\\RCA_LAT\n",
      "52 valid frames in C:\\Users\\root\\Data\\Angiographie\\MB-12\\export\\LCA_30LAO25CRA\n",
      "55 valid frames in C:\\Users\\root\\Data\\Angiographie\\MB-12\\export\\LCA_30RAO\n",
      "51 valid frames in C:\\Users\\root\\Data\\Angiographie\\MB-12\\export\\LCA_30RAO25CAU\n",
      "51 valid frames in C:\\Users\\root\\Data\\Angiographie\\MB-12\\export\\LCA_AP\n",
      "52 valid frames in C:\\Users\\root\\Data\\Angiographie\\MB-12\\export\\LCA_LAT\n",
      "46 valid frames in C:\\Users\\root\\Data\\Angiographie\\MJY-9\\export\\RCA_AP\n",
      "52 valid frames in C:\\Users\\root\\Data\\Angiographie\\MJY-9\\export\\RCA_LAT\n",
      "43 valid frames in C:\\Users\\root\\Data\\Angiographie\\SB-6\\export\\RCA_AP\n",
      "41 valid frames in C:\\Users\\root\\Data\\Angiographie\\SB-6\\export\\RCA_LAT\n",
      "39 valid frames in C:\\Users\\root\\Data\\Angiographie\\KR-11\\export\\LCA_30LAO25CAU\n",
      "42 valid frames in C:\\Users\\root\\Data\\Angiographie\\KR-11\\export\\LCA_30LAO25CRA\n",
      "41 valid frames in C:\\Users\\root\\Data\\Angiographie\\KR-11\\export\\LCA_30RAO\n",
      "50 valid frames in C:\\Users\\root\\Data\\Angiographie\\KR-11\\export\\LCA_AP\n",
      "45 valid frames in C:\\Users\\root\\Data\\Angiographie\\KR-11\\export\\LCA_LAT\n",
      "63 valid frames in C:\\Users\\root\\Data\\Angiographie\\KR-11\\export\\RCA_AP\n",
      "76 valid frames in C:\\Users\\root\\Data\\Angiographie\\KR-11\\export\\RCA_LAT\n"
     ]
    }
   ],
   "source": [
    "training_path = r'C:\\Users\\root\\Data\\Angiographie'\n",
    "validation_path = r'C:\\Users\\root\\Data\\Angiographie\\KR-11'\n",
    "training_set, validation_set = get_multisiamese_datasets(training_path, validation_path, 100, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mnist_trainset = datasets.MNIST(r\"C:\\Users\\root\\Data\\MNIST\", train=True, download=True, transform=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TripletMNIST(Dataset):\n",
    "    \"\"\"\n",
    "    Train: For each sample (anchor) randomly chooses a positive and negative samples\n",
    "    Test: Creates fixed triplets for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mnist_dataset):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.train = self.mnist_dataset.train\n",
    "        self.transform = self.mnist_dataset.transform\n",
    "\n",
    "        if self.train:\n",
    "            self.train_labels = self.mnist_dataset.train_labels\n",
    "            self.train_data = self.mnist_dataset.train_data\n",
    "            self.labels_set = set(self.train_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.train_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "        else:\n",
    "            self.test_labels = self.mnist_dataset.test_labels\n",
    "            self.test_data = self.mnist_dataset.test_data\n",
    "            # generate fixed triplets for testing\n",
    "            self.labels_set = set(self.test_labels.numpy())\n",
    "            self.label_to_indices = {label: np.where(self.test_labels.numpy() == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            triplets = [[i,\n",
    "                         random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
    "                         random_state.choice(self.label_to_indices[\n",
    "                                                 np.random.choice(\n",
    "                                                     list(self.labels_set - set([self.test_labels[i].item()]))\n",
    "                                                 )\n",
    "                                             ])\n",
    "                         ]\n",
    "                        for i in range(len(self.test_data))]\n",
    "            self.test_triplets = triplets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img1, label1 = self.train_data[index], self.train_labels[index].item()\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = np.random.choice(self.label_to_indices[label1])\n",
    "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "            img2 = self.train_data[positive_index]\n",
    "            img3 = self.train_data[negative_index]\n",
    "        else:\n",
    "            img1 = self.test_data[self.test_triplets[index][0]]\n",
    "            img2 = self.test_data[self.test_triplets[index][1]]\n",
    "            img3 = self.test_data[self.test_triplets[index][2]]\n",
    "\n",
    "        img1 = Image.fromarray(img1.numpy(), mode='L')\n",
    "        img2 = Image.fromarray(img2.numpy(), mode='L')\n",
    "        img3 = Image.fromarray(img3.numpy(), mode='L')\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img3 = self.transform(img3)\n",
    "        return (img1, img2, img3)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)\n",
    "    \n",
    "    \n",
    "triplet_mnist = TripletMNIST(mnist_trainset)\n",
    "train_loader = DataLoader(triplet_mnist, batch_size=20, shuffle=True, num_workers=0)\n",
    "# for batch_index, triplet in enumerate(train_loader):\n",
    "#     for i, image in enumerate(triplet):\n",
    "#         print(f\"batch {batch_index}, i {i}, triplet {image.numpy().shape}\")\n",
    "#         plt.subplot(1, 3, i+1)\n",
    "#         plt.imshow(image.view(224, 224).numpy())\n",
    "#         plt.title(\"Anchor\" if i == 0 else \"Positive\" if i == 1 else \"Negative\")\n",
    "#     plt.show()\n",
    "metrics = [EmbeddingL2DistanceMetric(), EmbeddingCosineSimilarityMetric()]\n",
    "fit(train_loader, None, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, start_epoch=start_epoch, save_progress_path=save_path, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_state_path = save_path + r\"\\training_state_0.pth\"\n",
    "print(load_state_path)\n",
    "state = torch.load(load_state_path)\n",
    "\n",
    "start_epoch = int(state['epoch']) + 1\n",
    "model.load_state_dict(state['model'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "scheduler.load_state_dict(state['scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Doesn't always work to free the GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angio sequence triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_set, batch_size=20, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(validation_set, batch_size=20, shuffle=True, num_workers=4)\n",
    "metrics = [EmbeddingL2DistanceMetric(), EmbeddingCosineSimilarityMetric()]\n",
    "fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, start_epoch=start_epoch, save_progress_path=save_path, metrics=metrics, measure_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angio sequence multisiamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n",
      "Will sample from train_loader\n",
      "Train: [0/100 (0%)]\tLoss: 1.982076\tElapsed time: 0:00:02.088481\tFCWeights (Diff, Avg, Total): (0.0, 0.026930220425128937, 882.449462890625)\n",
      "Epoch: 1/20. Train set: Average loss: 1.9901\tFCWeights (Diff, Avg, Total): (0.0, 0.026930220425128937, 882.449462890625)\n",
      "Starting Epoch 1\n",
      "Will sample from train_loader\n",
      "Train: [0/100 (0%)]\tLoss: 1.998081\tElapsed time: 0:00:00.230996\tFCWeights (Diff, Avg, Total): (0.0, 0.026930220425128937, 882.449462890625)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(training_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "val_loader = None  # DataLoader(validation_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "metrics = []  # [EmbeddingL2DistanceMetric(), EmbeddingCosineSimilarityMetric()]\n",
    "fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, start_epoch=start_epoch, save_progress_path=save_path, metrics=metrics, measure_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_state_path = save_path + r\"\\training_state_1.pth\"\n",
    "print(load_state_path)\n",
    "state = torch.load(load_state_path)\n",
    "model.load_state_dict(state['model'])\n",
    "model.eval()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'C:\\Users\\root\\Data\\Angiographie'\n",
    "test_set = get_test_set(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance_matrix(embeddings):\n",
    "    distances = []\n",
    "    for i in range(len(embeddings)):\n",
    "        distances_i = []\n",
    "        for j in range(len(embeddings)):\n",
    "            if j < i:\n",
    "                distances_i.append(distances[j][i])\n",
    "            elif j == i:\n",
    "                distances_i.append(0)\n",
    "            else:\n",
    "                val = torch.sum(torch.abs(embeddings[i] - embeddings[j]))\n",
    "                distances_i.append(val.cpu().numpy())\n",
    "        distances.append(distances_i)\n",
    "    distances = np.array(distances)\n",
    "    return distances\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "    for batch_index, sequences in enumerate(test_loader):\n",
    "        # sequences: (batch, video_frame, channel, width, height)\n",
    "        embeddings = []\n",
    "        print (f\"Batch {batch_index + 1}/{len(test_loader)} with {len(sequences[0])} sequences\")\n",
    "        for i in range(len(sequences[0])):\n",
    "            sequence = sequences[:, i]\n",
    "            embedding = model(sequence) # (1, 1000)\n",
    "            embeddings.append(embedding)\n",
    "        distance_matrix = calc_distance_matrix(embeddings)\n",
    "        plt.imshow(distance_matrix)\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"Distance matrix {distance_matrix.shape}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
